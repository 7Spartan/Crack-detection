{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwNv8jE-U5ce",
    "outputId": "58b3dd56-051c-4902-91e8-170424fcd273",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow\n",
    "import keras\n",
    "import scipy as sp\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
    "import glob\n",
    "\n",
    "# from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import os\n",
    "import pickle\n",
    "# import tqdm\n",
    "import itertools\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N35NfQ-RU5ch"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aof4LMFIU5cj"
   },
   "outputs": [],
   "source": [
    "def segment_img(img,stride,npw,nph):\n",
    "#     img = cv2.imread(img)\n",
    "    height,width, color = img.shape\n",
    "    test = 0\n",
    "    # print(height,width,color)\n",
    "#     orig = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    orig=img\n",
    "    num_strides_height = height/stride\n",
    "    num_strides_width = width/stride\n",
    "    rows = int(num_strides_height)\n",
    "    columns = int(num_strides_width)\n",
    "    blank_image = np.zeros((height,width), np.uint8)\n",
    "    # print(rows,columns)\n",
    "    for r in range(rows):\n",
    "        for c in range(columns):\n",
    "            x1 = (c)*stride\n",
    "            y1 = (r)*stride\n",
    "            x2 = x1+npw\n",
    "            y2 = y1+nph\n",
    "            if test == 0:\n",
    "                in_img = img[y1:y2,x1:x2]\n",
    "                if(len(in_img.shape)<3):\n",
    "#                     in_img = in_img.reshape(1,227,227,1)\n",
    "                    in_img = in_img/255\n",
    "                else:\n",
    "                    in_img = in_img.astype('uint8')\n",
    "#                     in_img = cv2.cvtColor(in_img,cv2.COLOR_RGB2GRAY)\n",
    "#                     in_img = in_img.reshape(1,227,227,1)\n",
    "                    in_img = in_img/255\n",
    "#The below line is used to predict\n",
    "                pred = model.predict(in_img[np.newaxis,:,:,:])\n",
    "                pred_class = np.argmax(pred)\n",
    "#                 result = model.predict(in_img, batch_size=None, verbose=0, steps=None)\n",
    "#                 re = result[0]\n",
    "                \n",
    "                if pred_class == 1:\n",
    "                    alpha = 0.25\n",
    "                    print('cracked')\n",
    "#                     print('confidence: ',re[0]*100,'%')\n",
    "#                     orig = cv2.rectangle(orig,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "                    out,le = cracklength(in_img)\n",
    "#                     out = plot_activation(in_img)\n",
    "#                     out = out*255\n",
    "#                     out = plt.imsave(\"crack.png\",out)\n",
    "#                     out = cv2.imread('crack.png')\n",
    "#                     out = cv2.applyColorMap(out, cv2.COLORMAP_JET)\n",
    "#                     out.shape\n",
    "#                     orig[y1:y2,x1:x2]=out\n",
    "                    cv2.addWeighted(out, alpha, orig[y1:y2,x1:x2], 1 - alpha,0, orig[y1:y2,x1:x2])\n",
    "#                     cv2.applyColorMap(out,orig[y1:y2,x1:x2],COLORMAP_JET)\n",
    "#                     blank_image[y1:y2,x1:x2] = out\n",
    "#                     orig[y1:y2,x1:x2]=out\n",
    "#                     orig=orig\n",
    "                else:\n",
    "                    jkl=0\n",
    "                    # print('no crack')\n",
    "            if ((width-x2 >= npw) or (width==npw)):\n",
    "                test = 0\n",
    "            else:\n",
    "                break\n",
    "        if ((height-y2) >= nph or (height==nph)):\n",
    "            test=0\n",
    "        else:\n",
    "            break\n",
    "#     orig = blank_image\n",
    "    \n",
    "    return(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activation(img):\n",
    "    pred = model.predict(img[np.newaxis,:,:,:])\n",
    "    pred_class = np.argmax(pred)\n",
    "  \n",
    "    weights = model.layers[-1].get_weights()[0]\n",
    "    class_weights = weights[:, pred_class]\n",
    "    intermediate = Model(inputs=model.input, outputs=model.get_layer(\"block5_conv3\").output)\n",
    "    conv_output = intermediate.predict(img[np.newaxis,:,:,:])\n",
    "    conv_output = np.squeeze(conv_output)\n",
    "  \n",
    "    h = int(img.shape[0]/conv_output.shape[0])\n",
    "    w = int(img.shape[1]/conv_output.shape[1])\n",
    "  \n",
    "    activation_maps = sp.ndimage.zoom(conv_output, (h, w, 1), order=1)\n",
    "    out = np.dot(activation_maps.reshape((img.shape[0]*img.shape[1], 512)), class_weights).reshape(img.shape[0],img.shape[1])\n",
    "#     plt.imshow(img.astype('float32').reshape(img.shape[0],img.shape[1],3))\n",
    "#     out = plt.imshow(out, cmap='jet', alpha=0.35)\n",
    "#     plt.title('Crack' if pred_class == 1 else 'No Crack')\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cracklength(img):\n",
    "    pix_width=1\n",
    "    # img=cv2.imread(img)\n",
    "    if (len(img)<3):\n",
    "        img = img\n",
    "    else:\n",
    "        # img=img.astype('unit8')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "    img = cv2.Canny(gray, 50, 100)\n",
    "    cv2.imwrite('Blur & Canny_2.png',img)\n",
    "    img = cv2.dilate(img, None, iterations=1)\n",
    "    cv2.imwrite('dialate_3.png',img)\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=4)\n",
    "    sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "    min_size = 800\n",
    "    img2 = np.zeros((output.shape))\n",
    "    for i in range(0, nb_components):\n",
    "        if sizes[i] >= min_size:\n",
    "            img2[output == i + 1] = 255\n",
    "    cv2.imwrite('test.png',img2)\n",
    "    cv2.imwrite('template_4.png',img2)\n",
    "    img = cv2.erode(img2, None, iterations=1)\n",
    "    #read the image with only crack\n",
    "    img2 = cv2.imread('C:/Users/deepa/Downloads/test.png')\n",
    "    img3 = cv2.bitwise_and(img2,orig_p)\n",
    "    img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
    "    img3 = cv2.dilate(img3, None, iterations=3)\n",
    "    ret,thresh = cv2.threshold(img3,127,255,0)\n",
    "    _,contours,hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "    n=len(contours)-1\n",
    "    cnt = contours[n]\n",
    "    (x,y),radius = cv2.minEnclosingCircle(cnt)\n",
    "    center = (int(x),int(y))\n",
    "    radius = int(radius)\n",
    "    cv2.circle(orig_p,center,radius,(255,255,255),2)\n",
    "    crack_length = radius*2*pix_width\n",
    "    cv2.imwrite('circle_5.png',orig_p)\n",
    "    print('Length of crack is ',crack_length,' centimeters')\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(orig_p,str(crack_length)+\" pxls\",(150,150),font,0.5,(0,255,255),2,cv2.LINE_AA)\n",
    "    # cv2.imshow(\"length\",orig_p)\n",
    "    cv2.imwrite('Length_6.png',orig_p)\n",
    "    return orig_p,crack_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vi8JV202U5cl",
    "outputId": "293798db-e725-4357-df49-9437571e3691",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n",
      "cracked\n"
     ]
    }
   ],
   "source": [
    "model = load_model('D:/SFU/Capstone/CD_V5.h5')\n",
    "cap = cv2.VideoCapture(0)\n",
    "stride = 120 #pixels to stride frwd or down\n",
    "#Shape of neural net dectectable image width x height\n",
    "neural_pixels_width = 224\n",
    "neural_pixels_height = 224\n",
    "npw = neural_pixels_width\n",
    "nph = neural_pixels_height\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    results = segment_img(frame,stride,npw,nph)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',results)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0acapnsnU5cn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Prototype_V5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
